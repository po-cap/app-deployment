#------------------------------------------------------------------------------
# CONNECTIONS AND AUTHENTICATION
#------------------------------------------------------------------------------
listen_addresses = '*'  # what IP address(es) to listen on;
                        # 如果設定成 “localhost” 的話，那就只有 localhost 可以與它連線
                        # 如果設定成 "IP" 那客戶端只能透過持有此 "IP" 的網卡與它連線
                        # 如果設定成 "*"，那客戶端呢以透過任意網卡與它連線
port = 5432
max_connections = 200               # pg_bouncer 會降低連線數
superuser_reserved_connections = 3  # 保留給 super user 做連線來排查故障用的
password_encryption = scram-sha-256 # scram-sha-256 or md5


#------------------------------------------------------------------------------
# 內存配置
#------------------------------------------------------------------------------
shared_buffers = {{ shared_buffers }}GB                  # 总内存的25%
work_mem = 16MB                       # 每个查询操作内存（排序、哈希操作會用到）
maintenance_work_mem = 512MB          # 维护操作内存（VACUUM 等操作會用到）


#------------------------------------------------------------------------------
# 優化 Query Planner
# 1) effective_cache_size
#   通常會設定成，系統剩餘內存的 50% ~ 70%
#   公式為 (Linux總內存 - shared_buffers - 其他應用內存) * 0.75
#   For Example:
#     系統內存 16GB
#     shared_buffers 4GB
#     其他應用 2GB
#     effective_cache_size = (16GB - 4GB - 2GB) * 75% = 7.5GB
#   值很大：傾向使用 index 做搜尋
#   值很小：傾向使用 seq scan 做搜尋
#
# 2) random_page_cost
#   一般建議：
#       HDD: 2.0
#       SSD: 1.1  
#   這個參數，是在計算 index scan cost 時會使用，背後的邏輯是，系統假設 Index Page 是
#   碎片化的，原因是當新資料插入時，索引可能需要重新組織，導致頁面分裂，摻生碎片。
#   當 Page 碎片化時，從 block device 上讀取這些 pages 的成本就上升了，尤其是對 HDD（
#   這也是為啥，HDD 的 random_page_cost 需要調大些的原因）
# 3) effective_io_concurrency
#   原理 
#     他會影響 
#        * 顺序扫描：控制预取多少后续数据块
#        * VACUUM 操作：影响清理过程的并行度
#        * CREATE INDEX：影响索引创建时的 I/O 并行度
#        * 备份操作：影响 pg_basebackup 等工具的 I/O 行为
#   推薦設置
#     * 傳統 HDD
#         2~4 機械硬盤病發速度有限
#         在機械硬盤下設定成 2，意味著 PostgreSQL 會提前讀取大約 2 個額外的數據塊
#     * SATA/SAS SSD
#         100~200 SSD 可以處理更高程度的併發 I/O
#     * NVMe SSD
#         200~300 高端設備可以設定在 300 以上
#         对 NVMe SSD 设置 effective_io_concurrency=256 则允许更激进的预读策略
#     * RAID 陣列
#         根據 RAID 磁盤數量調整，一般會設定在 RAID 磁盤數量 * 2 
#------------------------------------------------------------------------------
effective_cache_size = {{ cache_effective_size }}GB
random_page_cost = {{ 1.1 if is_SSD else 2.0  }}
effective_io_concurrency = {{ 200 if is_SSD else 2  }}




#------------------------------------------------------------------------------
# vacuum 配置
# 設定 autovacuum 的相關參數
# 以下情況會導致 autovacuum 被觸發
# 1) dead tuples 太多
#     * autovacuum_vacuum_threshould (可針對個別 table)
#           觸發 autovacuum 的 Dead Tuples 的基本數量
#           預設值是 50，但如果是高更新頻率可以改成 500 ~ 1000
#           ALTER TABLE large_table SET (autovacuum_vacuum_threshould = 100);
#     * autovacuum_vacuum_scale_factor (可針對個別 table)
#           觸發 autovacuum 的 Dead Tuples 的比例基數
#           預設值是 0.2，但如果是大表可以改成 0.05 ~ 0.1
#           ALTER TABLE large_table SET (autovacuum_vacuum_scale_factor = 0.05);
# 2) txid 使用的太多時
#     * autovacuum_freeze_max_age
#           距離上次的 freeze txid 後，用了多少 txids
#           預設值是 200,000,000，但如果是高更新頻率可以降低成 50,000,000~100,000,000
# 3) insert tuples 的數量
#           這部分，default 下是沒設置，也就是此項不引響 autovacuum
#
# 4) INSERT & UPDATE & DELETE 的 tuples 達到一定數量
#     由下列兩個參數控制
#           * autovacuum_analyze_threshold (default 50)
#               小表條大一點
#               ALTER TABLE small_table SET (autovacuum_vacuum_threshold = 200);
#           * autovacuum_analyze_scale_factor (default 0.2)
#               大表條小一點
#               ALTER TABLE large_table SET (autovacuum_vacuum_scale_factor = 0.05);
#
#
# autovacuum 成本控制
#      各種操作的成本明細
#        讀取頁面：1 點：從磁盤讀取一個 8KB 頁面
#        共享緩衝命中：0 點：頁面已在 shared_buffers 中
#        清理 dead tuples：100 點：處理一個頁面中的 dead tuples
#        寫入臟頁：5 點：將修改後的頁面寫回磁盤
#        凍結舊事務ID：額外成本：取決於凍結的元組數量
# 若累積成本到了 limit 值就會觸發休息，一次休息 delay 值
# 1) autovacuum_vacuum_cost_limit 
#     deafult 200 
# 2) autovacuum_vacuum_cost_delay
#     deafult 2ms 
# 下表是別人的實驗值
# | cost_limit | cost_delay | time(s) | IO read(MB/s)| IO Write(MB/s) |
# | ---------- | ---------- | ------- | ------------ | -------------- |
# | 200        | 20ms       | 7021    | 1.3          | 2.9            | 
# | 200        | 2ms        | 611     | 14           | 22             | 
# | 1000       | 2ms        | 90      | 100          | 41             | 
# | 2000       | 2ms        | 63      | 142          | 55             | 
# | 4000       | 2ms        | 50      | 180          | 71             | 
# | 10000      | 2ms        | 41      | 237          | 99             | 
# | 0          | 0          | 35      | 255          | 94             | 
# 這裏，我們得到一個結論 cost_delay 提升降低 I/O 負擔， cost_limit 提升升高 I/O 負擔
# 但是，若讓 I/O 負擔下降了，會增加表膨脹風險
# 典型生產環境下的 limit
#   * 中等負載系統：500-1000
#   * 高I/O能力系統：1000-2000
#   * 極高負載系統：2000-5000 (但需謹慎)
# 生攢環境下，一般把 delay 設定在 10ms ~ 50ms 之間
#------------------------------------------------------------------------------
#autovacuum_vacuum_threshold = 50 
#autovacuum_vacuum_scale_factor = 0.2 
#autovacuum_freeze_max_age = 200000000 

autovacuum_vacuum_cost_limit = 500
autovacuum_vacuum_cost_delay = 10ms
